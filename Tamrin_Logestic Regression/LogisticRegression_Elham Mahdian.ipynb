{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3facd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a21578f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6db564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "x = pd.DataFrame(data , columns = ['Pregnancies','Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'])\n",
    "y = data.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b34b9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test , y_train , y_test = train_test_split(x, y, test_size = 0.2 , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "829024fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = 'liblinear')\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7208f3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f38dabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr , tpr,_ = metrics.roc_curve(y_test , y_pred)\n",
    "plt.plot(fpr , tpr , label = 'data1')\n",
    "plt.legend(loc = 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9b521a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = logreg.predict_proba(x_test)[::, 1]\n",
    "fpr , tpr,_ = metrics.roc_curve(y_test , y_pred_proba)\n",
    "plt.plot(fpr , tpr , label = 'data1')\n",
    "plt.legend(loc = 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "76952c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "logreg.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4e4ef29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.4649764])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3466545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08777404,  0.02674251, -0.01798018,  0.00422995, -0.00086049,\n",
       "         0.05588317,  0.61727415,  0.01117764]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7557a445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33256172, 0.66743828],\n",
       "       [0.89268355, 0.10731645],\n",
       "       [0.25827885, 0.74172115],\n",
       "       ...,\n",
       "       [0.75643286, 0.24356714],\n",
       "       [0.66006778, 0.33993222],\n",
       "       [0.86614067, 0.13385933]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab55a692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29f36395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7747395833333334"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bcdb73a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[446,  54],\n",
       "       [119, 149]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y , logreg.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aaa9c8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y , logreg.predict(x))\n",
    "fig , ax = plt.subplots(figsize = (8 , 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks = (0 , 1), ticklabels = ('predicted 0s', 'predicted 1s'))\n",
    "ax.yaxis.set(ticks = (0 , 1), ticklabels = ('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5 , -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j , i , cm[i , j], ha = 'center', va = 'center', color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c11c971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       500\n",
      "           1       0.73      0.56      0.63       268\n",
      "\n",
      "    accuracy                           0.77       768\n",
      "   macro avg       0.76      0.72      0.74       768\n",
      "weighted avg       0.77      0.77      0.77       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y , logreg.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "577c69d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver = 'liblinear', C = 10.0 , random_state = 0)\n",
    "model.fit(x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b377fbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  \\\n",
       "0            0       80             72              0        0   23   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.5   30        0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'Pregnancies':[0],\n",
    "                    'Glucose':[80],\n",
    "                    'BloodPressure':[72],\n",
    "                    'SkinThickness':[0],\n",
    "                    'Insulin':[0],\n",
    "                    'BMI':[23],\n",
    "                    'DiabetesPedigreeFunction':[0.5],\n",
    "                    'Age':[30],\n",
    "                   'Outcome':[0]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c2ba3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "0              0       80             72              0        0  23.0   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "0                       0.500   30        0  \n",
       "\n",
       "[769 rows x 9 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data.append(df2)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c6f5a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=data2[['Pregnancies','Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']][:768]\n",
    "y_train = data2[['Outcome']][:768].values.reshape(-1 , 1)\n",
    "x_test = data2[['Pregnancies','Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']][768:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c295f7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression(solver = 'liblinear', C = 10.0 , random_state = 0)\n",
    "model2.fit(x_train,y_train.ravel())\n",
    "y_pred = model2.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8385369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "x = pd.DataFrame(data , columns = ['Pregnancies','Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'])\n",
    "y = data.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2ff58004",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test , y_train , y_test = train_test_split(x, y, test_size = 0.2 , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "208d4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() #saga solver requires features to be scaled for model conversion\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d230189d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver = 'saga')\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0850f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "41e2c21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver = 'sag')\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "82d6edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5cfee246",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'penalty':['l1','l2','elasticnet','none'],'solver':['liblinear']}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2e07366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= GridSearchCV(estimator=LogisticRegression(),param_grid=params,cv=10,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07ae8c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 459, in _check_solver\n",
      "    solver\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.73776634 0.72336174        nan        nan]\n",
      "  category=UserWarning,\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid.fit(x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9bb5fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, auc,roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7fe01",
   "metadata": {},
   "source": [
    "The best solver\n",
    "\n",
    "The model performs well on the train and testings sets, and both yield a similar accuracy of 0.79, and at a glance, there is no overfitting occur. Therefore, we start by selecting the best solver excluding regularization at this stage: {â€˜newton-cgâ€™, â€˜lbfgsâ€™, â€˜sagâ€™, â€˜sagaâ€™}.\n",
    "\n",
    "liblinear is excluded for the time being, as it does not support â€˜noneâ€™ penalty, and would log an error if we try: penalty == â€œnoneâ€: â†’ 464 raise ValueError(â€œpenalty=â€™noneâ€™ is not supported for the liblinear solverâ€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "70ab74d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.76221</td>\n",
       "      <td>0.82468</td>\n",
       "      <td>0.76316</td>\n",
       "      <td>0.61702</td>\n",
       "      <td>0.76645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.76221</td>\n",
       "      <td>0.82468</td>\n",
       "      <td>0.76316</td>\n",
       "      <td>0.61702</td>\n",
       "      <td>0.76645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.76221</td>\n",
       "      <td>0.82468</td>\n",
       "      <td>0.76316</td>\n",
       "      <td>0.61702</td>\n",
       "      <td>0.76645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76221</td>\n",
       "      <td>0.82468</td>\n",
       "      <td>0.76316</td>\n",
       "      <td>0.61702</td>\n",
       "      <td>0.76645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Test Accuracy  Precission   Recall      AUC\n",
       "0         0.76221        0.82468     0.76316  0.61702  0.76645\n",
       "1         0.76221        0.82468     0.76316  0.61702  0.76645\n",
       "2         0.76221        0.82468     0.76316  0.61702  0.76645\n",
       "3         0.76221        0.82468     0.76316  0.61702  0.76645"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = [\n",
    "    LogisticRegression(solver='newton-cg',penalty='none',max_iter=1000),\n",
    "    LogisticRegression(solver='lbfgs',penalty='none',max_iter=1000),\n",
    "    LogisticRegression(solver='sag',penalty='none',max_iter=1000),\n",
    "    LogisticRegression(solver='saga',penalty='none',max_iter=1000)\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(x_train, y_train).predict(x_test)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(x_train, y_train), 5)\n",
    "    clf_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(x_test, y_test), 5)\n",
    "    clf_compare.loc[row_index, 'Precission'] = round(precision_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'Recall'] = round(recall_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'AUC'] = round(auc(fp, tp),5)\n",
    "\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590dad4",
   "metadata": {},
   "source": [
    "Comparing Solvers with Penalties\n",
    "\n",
    "Next, we add a regularization l2 layer to all the solvers, including liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b34c7c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75896</td>\n",
       "      <td>0.81818</td>\n",
       "      <td>0.77143</td>\n",
       "      <td>0.57447</td>\n",
       "      <td>0.74985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75896</td>\n",
       "      <td>0.81818</td>\n",
       "      <td>0.77143</td>\n",
       "      <td>0.57447</td>\n",
       "      <td>0.74985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75896</td>\n",
       "      <td>0.81818</td>\n",
       "      <td>0.77143</td>\n",
       "      <td>0.57447</td>\n",
       "      <td>0.74985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75896</td>\n",
       "      <td>0.81818</td>\n",
       "      <td>0.77143</td>\n",
       "      <td>0.57447</td>\n",
       "      <td>0.74985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Test Accuracy  Precission   Recall      AUC\n",
       "0         0.75896        0.81818     0.77143  0.57447  0.74985\n",
       "1         0.75896        0.81818     0.77143  0.57447  0.74985\n",
       "2         0.75896        0.81818     0.77143  0.57447  0.74985\n",
       "3         0.75896        0.81818     0.77143  0.57447  0.74985"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = [\n",
    "    LogisticRegression(solver='newton-cg',penalty='l2',max_iter=1000),\n",
    "    LogisticRegression(solver='lbfgs',penalty='l2',max_iter=1000),\n",
    "    LogisticRegression(solver='sag',penalty='l2',max_iter=1000),\n",
    "    LogisticRegression(solver='saga',penalty='l2',max_iter=1000)\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(x_train, y_train).predict(x_test)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(x_train, y_train), 5)\n",
    "    clf_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(x_test, y_test), 5)\n",
    "    clf_compare.loc[row_index, 'Precission'] = round(precision_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'Recall'] = round(recall_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'AUC'] = round(auc(fp, tp),5)\n",
    "\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9e69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6e9695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.64007</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.64007</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64007</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.64007</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Test Accuracy  Precission  Recall  AUC\n",
       "0         0.64007        0.69481         0.0     0.0  0.5\n",
       "1         0.64007        0.69481         0.0     0.0  0.5\n",
       "2         0.64007        0.69481         0.0     0.0  0.5\n",
       "3         0.64007        0.69481         0.0     0.0  0.5"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = [\n",
    "    LogisticRegression(solver='newton-cg',penalty='l2', C=0.001, max_iter=1000),\n",
    "    LogisticRegression(solver='lbfgs',penalty='l2',C=0.001, max_iter=1000),\n",
    "    LogisticRegression(solver='sag',penalty='l2',C=0.001, max_iter=1000),\n",
    "    LogisticRegression(solver='saga',penalty='l2',C=0.001, max_iter=1000)\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(x_train, y_train).predict(x_test)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(x_train, y_train), 5)\n",
    "    clf_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(x_test, y_test), 5)\n",
    "    clf_compare.loc[row_index, 'Precission'] = round(precision_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'Recall'] = round(recall_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'AUC'] = round(auc(fp, tp),5)\n",
    "\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bfb384ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "X = pd.DataFrame(data , columns = ['Pregnancies','Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'])\n",
    "y = data.Outcome\n",
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dd265296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.79\n",
      "Accuracy of logistic regression classifier on test set: 0.74\n",
      "Precision of logistic regression classifier on test set: 0.69\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "scaler = MinMaxScaler() #saga solver requires features to be scaled for model conversion\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "print('Precision of logistic regression classifier on test set: {:.2f}'.format(precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5f613da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7934</td>\n",
       "      <td>0.73438</td>\n",
       "      <td>0.64815</td>\n",
       "      <td>0.52239</td>\n",
       "      <td>0.68519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7934</td>\n",
       "      <td>0.73438</td>\n",
       "      <td>0.64815</td>\n",
       "      <td>0.52239</td>\n",
       "      <td>0.68519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7934</td>\n",
       "      <td>0.73438</td>\n",
       "      <td>0.64815</td>\n",
       "      <td>0.52239</td>\n",
       "      <td>0.68519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7934</td>\n",
       "      <td>0.73438</td>\n",
       "      <td>0.64815</td>\n",
       "      <td>0.52239</td>\n",
       "      <td>0.68519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Test Accuracy  Precission   Recall      AUC\n",
       "0          0.7934        0.73438     0.64815  0.52239  0.68519\n",
       "1          0.7934        0.73438     0.64815  0.52239  0.68519\n",
       "2          0.7934        0.73438     0.64815  0.52239  0.68519\n",
       "3          0.7934        0.73438     0.64815  0.52239  0.68519"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = [\n",
    "    LogisticRegression(solver='newton-cg',penalty='none',max_iter=1000),\n",
    "    LogisticRegression(solver='lbfgs',penalty='none',max_iter=1000),\n",
    "    LogisticRegression(solver='sag',penalty='none',max_iter=1000),\n",
    "    LogisticRegression(solver='saga',penalty='none',max_iter=1000)\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(X_train, y_train), 5)\n",
    "    clf_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(X_test, y_test), 5)\n",
    "    clf_compare.loc[row_index, 'Precission'] = round(precision_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'Recall'] = round(recall_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'AUC'] = round(auc(fp, tp),5)\n",
    "\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d10e0633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.78819</td>\n",
       "      <td>0.74479</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.49254</td>\n",
       "      <td>0.68627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.78819</td>\n",
       "      <td>0.74479</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.49254</td>\n",
       "      <td>0.68627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.78819</td>\n",
       "      <td>0.74479</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.49254</td>\n",
       "      <td>0.68627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.78819</td>\n",
       "      <td>0.74479</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.49254</td>\n",
       "      <td>0.68627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Test Accuracy  Precission   Recall      AUC\n",
       "0         0.78819        0.74479      0.6875  0.49254  0.68627\n",
       "1         0.78819        0.74479      0.6875  0.49254  0.68627\n",
       "2         0.78819        0.74479      0.6875  0.49254  0.68627\n",
       "3         0.78819        0.74479      0.6875  0.49254  0.68627"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparing Solvers with Penalties\n",
    "clf = [\n",
    "    LogisticRegression(solver='newton-cg',penalty='l2',max_iter=1000),\n",
    "    LogisticRegression(solver='lbfgs',penalty='l2',max_iter=1000),\n",
    "    LogisticRegression(solver='sag',penalty='l2',max_iter=1000),\n",
    "    LogisticRegression(solver='saga',penalty='l2',max_iter=1000)\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(X_train, y_train), 5)\n",
    "    clf_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(X_test, y_test), 5)\n",
    "    clf_compare.loc[row_index, 'Precission'] = round(precision_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'Recall'] = round(recall_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'AUC'] = round(auc(fp, tp),5)\n",
    "\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "713124c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65104</td>\n",
       "      <td>0.65104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.65104</td>\n",
       "      <td>0.65104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.65104</td>\n",
       "      <td>0.65104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.65104</td>\n",
       "      <td>0.65104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Accuracy  Test Accuracy  Precission  Recall  AUC\n",
       "0         0.65104        0.65104         0.0     0.0  0.5\n",
       "1         0.65104        0.65104         0.0     0.0  0.5\n",
       "2         0.65104        0.65104         0.0     0.0  0.5\n",
       "3         0.65104        0.65104         0.0     0.0  0.5"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparing C\n",
    "clf = [\n",
    "    LogisticRegression(solver='newton-cg',penalty='l2', C=0.001, max_iter=1000),\n",
    "    LogisticRegression(solver='lbfgs',penalty='l2',C=0.001, max_iter=1000),\n",
    "    LogisticRegression(solver='sag',penalty='l2',C=0.001, max_iter=1000),\n",
    "    LogisticRegression(solver='saga',penalty='l2',C=0.001, max_iter=1000)\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(X_train, y_train), 5)\n",
    "    clf_compare.loc[row_index, 'Test Accuracy'] = round(alg.score(X_test, y_test), 5)\n",
    "    clf_compare.loc[row_index, 'Precission'] = round(precision_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'Recall'] = round(recall_score(y_test, predicted),5)\n",
    "    clf_compare.loc[row_index, 'AUC'] = round(auc(fp, tp),5)\n",
    "\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "63c536c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = LogisticRegression()\n",
    "parameters = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000],\n",
    "             'max_iter' : [10,100,500]} \n",
    "\n",
    "best_model = GridSearchCV(model, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0bd1b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "105 fits failed out of a total of 210.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.65104948        nan 0.65104948        nan 0.65104948\n",
      "        nan 0.65104948        nan 0.65104948        nan 0.65104948\n",
      "        nan 0.67361319        nan 0.67361319        nan 0.67361319\n",
      "        nan 0.78127436        nan 0.78127436        nan 0.78127436\n",
      "        nan 0.7829985         nan 0.7829985         nan 0.7829985\n",
      "        nan 0.77781109        nan 0.77781109        nan 0.77781109\n",
      "        nan 0.77781109        nan 0.77781109        nan 0.77781109]\n",
      "  category=UserWarning,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'max_iter': [10, 100, 500], 'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ec942d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7395833333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "105 fits failed out of a total of 210.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.65104948        nan 0.65104948        nan 0.65104948\n",
      "        nan 0.65104948        nan 0.65104948        nan 0.65104948\n",
      "        nan 0.67361319        nan 0.67361319        nan 0.67361319\n",
      "        nan 0.78127436        nan 0.78127436        nan 0.78127436\n",
      "        nan 0.7829985         nan 0.7829985         nan 0.7829985\n",
      "        nan 0.77781109        nan 0.77781109        nan 0.77781109\n",
      "        nan 0.77781109        nan 0.77781109        nan 0.77781109]\n",
      "  category=UserWarning,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "model = best_model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "model_score = model.score(X_test, y_test)\n",
    "\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e7c26c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logModel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1e64a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ae9891e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b05ff728",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(logModel, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f6886e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2160 fits failed out of a total of 4800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 459, in _check_solver\n",
      "    solver\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1473, in fit\n",
      "    % self.l1_ratio\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.65104167 ...        nan 0.69140625 0.68229167]\n",
      "  category=UserWarning,\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "C:\\Users\\Elham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "best_clf = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "938475db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d5d26d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - : 0.783\n"
     ]
    }
   ],
   "source": [
    "print (f'Accuracy - : {best_clf.score(X,y):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0fe6f754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8decbacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
